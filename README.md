See slides at 
https://docs.google.com/presentation/d/1P9MH_pYsJnmArSpUqTD-EnNtstcDyD-MH1mZkhcQ9oo/edit?usp=sharing


For exercise 1, include the code
For exercises 2.1-2.5, include the code and any images you find relevant
For 2.3-2.5 include a small comment as well explaining your results.

Zip results and email me at:
ryan.webster@unicaen.fr

Finally, answer the following questions:

2.6: 
Why does y_feats have the same dimension regardless of what scale we use?

2.7:
Synthesize an image with different numbers of scales, what is the effect of having more/ less scales?


Exercise 4 - Texture analysis:

Synthesize raddish and stones images with the three techniques you've learned:
(1) Patch based (with julien)
(2) Neural synthesis with VGG gram matrices
(3) Feedforward synthesis

4.1: Compute the VGG Gram matrix for each.

4.2: Analyze the Synthesis algorithms in terms of visual quality, loss and computation time.
What are the advantages and disadvantages of each?

For your report I would like:

Synthesize a small report. Include your answers for each exercise (2.3-2.7), 4.1-4.2. Finally include a short description of each algorithm as well as the synthesized images from each (Including Patch based algorithm). 

Due Wednesday Feb. 19th!

*4.3: Compute the position maps (see slides) of each image using the algorithm from (1). Provide a small analysis.

*Exercise 5 (if time, extra credxit):

Fork the github repo:
https://github.com/leongatys/PytorchNeuralStyleTransfer

*5.1: Run the style transfer on an content / style image.

*5.2: Analyze the loss, what is the difference between the content loss and style loss?

*5.3: Why is the Gram Matrix loss more suitable for textures?


References:
Texture Synthesis with Convolutional Neural Networks:
https://arxiv.org/abs/1505.07376

Texture Networks:
https://arxiv.org/abs/1603.03417
